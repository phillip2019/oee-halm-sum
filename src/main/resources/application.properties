# job name
job.name=oee-halm-sum

#FlinkUtils配置
bootstrap.servers=172.16.111.20:9092,172.16.111.21:9092,172.16.111.22:9092
# ZooKeeper集群地址
zookeeper.connect=172.16.111.20:2181,172.16.111.21:2181,172.16.111.22:2181

# Kafka Topic名称
job.etl.source.topic=data-collection-halm-yw
# 测试的group id
job.etl.source.group.id=etl_oee_halm_sum_test
# 正式环境的group id
# job.etl.source.group.id=etl_df_sxw_prod
# 自动提交拉取到消费端的消息offset到kafka
job.etl.source.enable.auto.commit=true
# 自动提交offset到zookeeper的时间间隔单位（毫秒）
job.etl.source.auto.commit.interval.ms=5000
# 每次消费最新的数据
job.etl.source.auto.offset.reset=earliest
# checkpoint位置
job.checkpoint.Data.Uri=hdfs://172.16.98.85:8020/flink-checkpoint

#写入Hbase的配置
# Hbase在线表名
job.online.hbase.table=ods:ods_f_eqp_ct_oee_halmyw_sum
